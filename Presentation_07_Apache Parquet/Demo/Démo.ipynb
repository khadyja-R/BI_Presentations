{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdc74d06-967e-4440-af80-d5e2931dd12c",
   "metadata": {},
   "source": [
    "### Installation et Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b460356c-19c9-4bad-8a72-dd423c9481e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D√©monstration Parquet Simplifi√©e - NYC Taxi Data\n"
     ]
    }
   ],
   "source": [
    "# Requirements d'installation\n",
    "# pip install pandas pyarrow fastparquet\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "print(\"D√©monstration Parquet Simplifi√©e - NYC Taxi Data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2146148-e871-4fa7-977c-9540c086e09a",
   "metadata": {},
   "source": [
    "### Fonctions de T√©l√©chargement et Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6300a56-e339-4aed-b4f6-f9a817495a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_taxi_data():\n",
    "    \"\"\"T√©l√©charge les donn√©es NYC Taxi 2025 ou cr√©e des donn√©es simul√©es\"\"\"\n",
    "    \n",
    "    # URLs des donn√©es NYC Taxi 2025\n",
    "    urls_2025 = [\n",
    "        \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-01.parquet\",\n",
    "        \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-12.parquet\",\n",
    "        \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-11.parquet\"\n",
    "    ]\n",
    "    \n",
    "    for url in urls_2025:\n",
    "        try:\n",
    "            print(f\"üì• Tentative de t√©l√©chargement: {url.split('/')[-1]}\")\n",
    "            df = pd.read_parquet(url)\n",
    "            print(f\"Donn√©es t√©l√©charg√©es: {len(df):,} lignes\")\n",
    "            return df.head(50000)  # Limiter pour la d√©mo\n",
    "        except Exception as e:\n",
    "            print(f\" Erreur: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"Tous les t√©l√©chargements ont √©chou√©, cr√©ation de donn√©es simul√©es...\")\n",
    "    return create_simulated_taxi_data()\n",
    "\n",
    "def create_simulated_taxi_data(n_rows=50000):\n",
    "    \"\"\"Cr√©e des donn√©es de taxi simul√©es NYC style\"\"\"\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    data = {\n",
    "        'tpep_pickup_datetime': pd.date_range('2025-01-01', periods=n_rows, freq='1min'),\n",
    "        'tpep_dropoff_datetime': pd.date_range('2025-01-01 00:10:00', periods=n_rows, freq='1min'),\n",
    "        'passenger_count': np.random.choice([1, 2, 3, 4, 5], n_rows, p=[0.5, 0.3, 0.1, 0.05, 0.05]),\n",
    "        'trip_distance': np.random.exponential(2.5, n_rows),\n",
    "        'fare_amount': np.random.gamma(2, 5, n_rows),\n",
    "        'extra': np.random.choice([0, 0.5, 1], n_rows, p=[0.7, 0.2, 0.1]),\n",
    "        'tip_amount': np.random.gamma(1, 2, n_rows),\n",
    "        'total_amount': np.random.gamma(3, 7, n_rows),\n",
    "        'pickup_location_id': np.random.randint(1, 265, n_rows),\n",
    "        'dropoff_location_id': np.random.randint(1, 265, n_rows),\n",
    "        'payment_type': np.random.choice([1, 2, 3, 4], n_rows, p=[0.6, 0.3, 0.05, 0.05])\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df['total_amount'] = df['fare_amount'] + df['tip_amount'] + df['extra']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74afb1da-9731-437e-9e73-64744e63eb73",
   "metadata": {},
   "source": [
    "### Chargement des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cda8b027-b81e-4c12-b1fb-e3bf6e4ea1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Tentative de t√©l√©chargement: yellow_tripdata_2025-01.parquet\n",
      "Donn√©es t√©l√©charg√©es: 3,475,226 lignes\n",
      "üìä Dataset: 50,000 lignes, 20 colonnes\n",
      "\n",
      "üìã Aper√ßu des donn√©es:\n",
      "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
      "0         1  2025-01-01 00:18:38   2025-01-01 00:26:59              1.0   \n",
      "1         1  2025-01-01 00:32:40   2025-01-01 00:35:13              1.0   \n",
      "2         1  2025-01-01 00:44:04   2025-01-01 00:46:01              1.0   \n",
      "3         2  2025-01-01 00:14:27   2025-01-01 00:20:01              3.0   \n",
      "4         2  2025-01-01 00:21:34   2025-01-01 00:25:06              3.0   \n",
      "\n",
      "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
      "0           1.60         1.0                  N           229           237   \n",
      "1           0.50         1.0                  N           236           237   \n",
      "2           0.60         1.0                  N           141           141   \n",
      "3           0.52         1.0                  N           244           244   \n",
      "4           0.66         1.0                  N           244           116   \n",
      "\n",
      "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
      "0             1         10.0    3.5      0.5        3.00           0.0   \n",
      "1             1          5.1    3.5      0.5        2.02           0.0   \n",
      "2             1          5.1    3.5      0.5        2.00           0.0   \n",
      "3             2          7.2    1.0      0.5        0.00           0.0   \n",
      "4             2          5.8    1.0      0.5        0.00           0.0   \n",
      "\n",
      "   improvement_surcharge  total_amount  congestion_surcharge  Airport_fee  \\\n",
      "0                    1.0         18.00                   2.5          0.0   \n",
      "1                    1.0         12.12                   2.5          0.0   \n",
      "2                    1.0         12.10                   2.5          0.0   \n",
      "3                    1.0          9.70                   0.0          0.0   \n",
      "4                    1.0          8.30                   0.0          0.0   \n",
      "\n",
      "   cbd_congestion_fee  \n",
      "0                 0.0  \n",
      "1                 0.0  \n",
      "2                 0.0  \n",
      "3                 0.0  \n",
      "4                 0.0  \n",
      "\n",
      "üìä Info sur le dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   VendorID               50000 non-null  int32         \n",
      " 1   tpep_pickup_datetime   50000 non-null  datetime64[us]\n",
      " 2   tpep_dropoff_datetime  50000 non-null  datetime64[us]\n",
      " 3   passenger_count        50000 non-null  float64       \n",
      " 4   trip_distance          50000 non-null  float64       \n",
      " 5   RatecodeID             50000 non-null  float64       \n",
      " 6   store_and_fwd_flag     50000 non-null  object        \n",
      " 7   PULocationID           50000 non-null  int32         \n",
      " 8   DOLocationID           50000 non-null  int32         \n",
      " 9   payment_type           50000 non-null  int64         \n",
      " 10  fare_amount            50000 non-null  float64       \n",
      " 11  extra                  50000 non-null  float64       \n",
      " 12  mta_tax                50000 non-null  float64       \n",
      " 13  tip_amount             50000 non-null  float64       \n",
      " 14  tolls_amount           50000 non-null  float64       \n",
      " 15  improvement_surcharge  50000 non-null  float64       \n",
      " 16  total_amount           50000 non-null  float64       \n",
      " 17  congestion_surcharge   50000 non-null  float64       \n",
      " 18  Airport_fee            50000 non-null  float64       \n",
      " 19  cbd_congestion_fee     50000 non-null  float64       \n",
      "dtypes: datetime64[us](2), float64(13), int32(3), int64(1), object(1)\n",
      "memory usage: 7.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Chargement des donn√©es\n",
    "taxi_df = download_taxi_data()\n",
    "print(f\"üìä Dataset: {taxi_df.shape[0]:,} lignes, {taxi_df.shape[1]} colonnes\")\n",
    "\n",
    "# Aper√ßu des donn√©es\n",
    "print(\"\\nüìã Aper√ßu des donn√©es:\")\n",
    "print(taxi_df.head())\n",
    "print(f\"\\nüìä Info sur le dataset:\")\n",
    "print(taxi_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a494428-8711-41c2-beaf-9a87d323cb40",
   "metadata": {},
   "source": [
    "### Sauvegarde en Diff√©rents Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2fa77a1-b411-4a17-bb8a-640e4acc9ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üíæ SAUVEGARDE EN DIFF√âRENTS FORMATS\n",
      "============================================================\n",
      "üìÑ Sauvegarde CSV...\n",
      "üì¶ Sauvegarde Parquet (sans compression)...\n",
      "üì¶ Sauvegarde Parquet (Snappy)...\n",
      "üì¶ Sauvegarde Parquet (Gzip)...\n",
      "‚úÖ Toutes les sauvegardes termin√©es!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üíæ SAUVEGARDE EN DIFF√âRENTS FORMATS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# CSV\n",
    "print(\"üìÑ Sauvegarde CSV...\")\n",
    "start_time = time.time()\n",
    "taxi_df.to_csv(\"taxi_data.csv\", index=False)\n",
    "csv_time = time.time() - start_time\n",
    "csv_size = os.path.getsize(\"taxi_data.csv\") / 1024**2\n",
    "\n",
    "# Parquet avec diff√©rentes compressions\n",
    "print(\"üì¶ Sauvegarde Parquet (sans compression)...\")\n",
    "start_time = time.time()\n",
    "taxi_df.to_parquet(\"taxi_data_none.parquet\", compression=None)\n",
    "parquet_none_time = time.time() - start_time\n",
    "parquet_none_size = os.path.getsize(\"taxi_data_none.parquet\") / 1024**2\n",
    "\n",
    "print(\"üì¶ Sauvegarde Parquet (Snappy)...\")\n",
    "start_time = time.time()\n",
    "taxi_df.to_parquet(\"taxi_data_snappy.parquet\", compression='snappy')\n",
    "parquet_snappy_time = time.time() - start_time\n",
    "parquet_snappy_size = os.path.getsize(\"taxi_data_snappy.parquet\") / 1024**2\n",
    "\n",
    "print(\"üì¶ Sauvegarde Parquet (Gzip)...\")\n",
    "start_time = time.time()\n",
    "taxi_df.to_parquet(\"taxi_data_gzip.parquet\", compression='gzip')\n",
    "parquet_gzip_time = time.time() - start_time\n",
    "parquet_gzip_size = os.path.getsize(\"taxi_data_gzip.parquet\") / 1024**2\n",
    "\n",
    "print(\"‚úÖ Toutes les sauvegardes termin√©es!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f535b366-4da6-4fb0-9077-c2305e8d58f9",
   "metadata": {},
   "source": [
    "### Comparaison des Tailles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3240218e-deb4-4895-b8b9-c7a13ad2a543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìè COMPARAISON DES TAILLES\n",
      "============================================================\n",
      "Format                | Taille (MB)  | Ratio vs CSV\n",
      "-----------------------------------------------------------------\n",
      "CSV                   |      5.3     | 1.0x\n",
      "Parquet (aucune)      |      1.2     | 4.3x\n",
      "Parquet (Snappy)      |      1.1     | 5.0x\n",
      "Parquet (Gzip)        |      0.8     | 6.2x\n",
      "\n",
      "üèÜ Meilleure compression: 6.2x plus compact\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìè COMPARAISON DES TAILLES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"Format                | Taille (MB)  | Ratio vs CSV\")\n",
    "print(\"-\" * 65)\n",
    "print(f\"CSV                   | {csv_size:8.1f}     | 1.0x\")\n",
    "print(f\"Parquet (aucune)      | {parquet_none_size:8.1f}     | {csv_size/parquet_none_size:.1f}x\")\n",
    "print(f\"Parquet (Snappy)      | {parquet_snappy_size:8.1f}     | {csv_size/parquet_snappy_size:.1f}x\")\n",
    "print(f\"Parquet (Gzip)        | {parquet_gzip_size:8.1f}     | {csv_size/parquet_gzip_size:.1f}x\")\n",
    "\n",
    "print(f\"\\nüèÜ Meilleure compression: {csv_size/min(parquet_none_size, parquet_snappy_size, parquet_gzip_size):.1f}x plus compact\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f3680c-6b52-44b8-85b7-5640c0838f96",
   "metadata": {},
   "source": [
    "### Performance de Lecture Compl√®te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d952e64b-9135-411d-adce-5847e3fccc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "‚ö° PERFORMANCE DE LECTURE\n",
      "============================================================\n",
      "üìñ Test lecture CSV...\n",
      "üìñ Test lecture Parquet...\n",
      "\n",
      "Format    | Temps lecture | Lignes\n",
      "----------------------------------------\n",
      "CSV       |     0.49s     | 50,000\n",
      "Parquet   |     0.04s     | 50,000\n",
      "\n",
      "üöÄ Parquet est 11.9x plus rapide pour la lecture\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚ö° PERFORMANCE DE LECTURE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Lecture compl√®te CSV\n",
    "print(\"üìñ Test lecture CSV...\")\n",
    "start_time = time.time()\n",
    "df_csv = pd.read_csv(\"taxi_data.csv\")\n",
    "csv_read_time = time.time() - start_time\n",
    "\n",
    "# Lecture compl√®te Parquet\n",
    "print(\"üìñ Test lecture Parquet...\")\n",
    "start_time = time.time()\n",
    "df_parquet = pd.read_parquet(\"taxi_data_snappy.parquet\")\n",
    "parquet_read_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nFormat    | Temps lecture | Lignes\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"CSV       | {csv_read_time:8.2f}s     | {len(df_csv):,}\")\n",
    "print(f\"Parquet   | {parquet_read_time:8.2f}s     | {len(df_parquet):,}\")\n",
    "print(f\"\\nüöÄ Parquet est {csv_read_time/parquet_read_time:.1f}x plus rapide pour la lecture\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d85c7ee-95dd-4f99-8d70-603f77e10e9c",
   "metadata": {},
   "source": [
    "### Performance de Filtrage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ce51be4-4e42-4633-baab-ea774b939fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üîç PERFORMANCE DE FILTRAGE\n",
      "============================================================\n",
      "üéØ Test: Courses avec total_amount > 20$\n",
      "\n",
      "M√©thode           | Temps    | Lignes r√©sultat\n",
      "---------------------------------------------\n",
      "CSV (full+filter) |   0.49s | 25,095\n",
      "Parquet (filter)  |   0.03s | 25,095\n",
      "\n",
      "üöÄ Parquet filtrage est 15.7x plus rapide\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üîç PERFORMANCE DE FILTRAGE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test: Courses avec montant > 20$\n",
    "print(\"üéØ Test: Courses avec total_amount > 20$\")\n",
    "\n",
    "# Filtrage CSV (lecture compl√®te puis filtrage)\n",
    "start_time = time.time()\n",
    "df_csv_full = pd.read_csv(\"taxi_data.csv\")\n",
    "df_csv_filtered = df_csv_full[df_csv_full['total_amount'] > 20]\n",
    "csv_filter_time = time.time() - start_time\n",
    "\n",
    "# Filtrage Parquet (avec predicate pushdown)\n",
    "start_time = time.time()\n",
    "df_parquet_filtered = pd.read_parquet(\"taxi_data_snappy.parquet\", \n",
    "                                     filters=[('total_amount', '>', 20)])\n",
    "parquet_filter_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nM√©thode           | Temps    | Lignes r√©sultat\")\n",
    "print(\"-\" * 45)\n",
    "print(f\"CSV (full+filter) | {csv_filter_time:6.2f}s | {len(df_csv_filtered):,}\")\n",
    "print(f\"Parquet (filter)  | {parquet_filter_time:6.2f}s | {len(df_parquet_filtered):,}\")\n",
    "print(f\"\\nüöÄ Parquet filtrage est {csv_filter_time/parquet_filter_time:.1f}x plus rapide\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536740c2-d88a-4ae3-97c0-87abbb4a797a",
   "metadata": {},
   "source": [
    "### Performance de Lecture par Colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed43c52f-05f5-435b-aaf9-b3663b73f03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Test: Lecture colonnes sp√©cifiques\n",
      "\n",
      "M√©thode           | Temps    | Colonnes\n",
      "----------------------------------------\n",
      "CSV colonnes      |   0.35s | 3\n",
      "Parquet colonnes  |   0.01s | 3\n",
      "\n",
      "üöÄ Parquet colonnes est 24.2x plus rapide\n",
      "\n",
      "üìã Aper√ßu des colonnes lues:\n",
      "  tpep_pickup_datetime  passenger_count  total_amount\n",
      "0  2025-01-01 00:18:38              1.0         18.00\n",
      "1  2025-01-01 00:32:40              1.0         12.12\n",
      "2  2025-01-01 00:44:04              1.0         12.10\n",
      "3  2025-01-01 00:14:27              3.0          9.70\n",
      "4  2025-01-01 00:21:34              3.0          8.30\n"
     ]
    }
   ],
   "source": [
    "# Test: Lecture colonnes sp√©cifiques\n",
    "print(f\"\\nüéØ Test: Lecture colonnes sp√©cifiques\")\n",
    "columns_to_read = ['tpep_pickup_datetime', 'passenger_count', 'total_amount']\n",
    "\n",
    "# CSV - colonnes sp√©cifiques\n",
    "start_time = time.time()\n",
    "df_csv_cols = pd.read_csv(\"taxi_data.csv\", usecols=columns_to_read)\n",
    "csv_cols_time = time.time() - start_time\n",
    "\n",
    "# Parquet - colonnes sp√©cifiques\n",
    "start_time = time.time()\n",
    "df_parquet_cols = pd.read_parquet(\"taxi_data_snappy.parquet\", columns=columns_to_read)\n",
    "parquet_cols_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nM√©thode           | Temps    | Colonnes\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"CSV colonnes      | {csv_cols_time:6.2f}s | {len(df_csv_cols.columns)}\")\n",
    "print(f\"Parquet colonnes  | {parquet_cols_time:6.2f}s | {len(df_parquet_cols.columns)}\")\n",
    "print(f\"\\nüöÄ Parquet colonnes est {csv_cols_time/parquet_cols_time:.1f}x plus rapide\")\n",
    "\n",
    "# Aper√ßu des donn√©es lues\n",
    "print(f\"\\nüìã Aper√ßu des colonnes lues:\")\n",
    "print(df_parquet_cols.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5829c3c-70bf-45ca-a4cd-6000a8ac9d93",
   "metadata": {},
   "source": [
    " ### M√©tadonn√©es Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7e55c18-3d4f-45a5-8d4f-2dc21f35d76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìã M√âTADONN√âES PARQUET\n",
      "============================================================\n",
      "üîç INFORMATIONS G√âN√âRALES:\n",
      "  Nombre de lignes: 50,000\n",
      "  Nombre de colonnes: 20\n",
      "  Nombre de row groups: 1\n",
      "  Taille fichier: 1.1 MB\n",
      "  Compression: SNAPPY\n",
      "\n",
      "üìä SCHEMA DES COLONNES:\n",
      "  VendorID                  | int32\n",
      "  tpep_pickup_datetime      | timestamp[us]\n",
      "  tpep_dropoff_datetime     | timestamp[us]\n",
      "  passenger_count           | double\n",
      "  trip_distance             | double\n",
      "  RatecodeID                | double\n",
      "  store_and_fwd_flag        | string\n",
      "  PULocationID              | int32\n",
      "  DOLocationID              | int32\n",
      "  payment_type              | int64\n",
      "  fare_amount               | double\n",
      "  extra                     | double\n",
      "  mta_tax                   | double\n",
      "  tip_amount                | double\n",
      "  tolls_amount              | double\n",
      "  improvement_surcharge     | double\n",
      "  total_amount              | double\n",
      "  congestion_surcharge      | double\n",
      "  Airport_fee               | double\n",
      "  cbd_congestion_fee        | double\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìã M√âTADONN√âES PARQUET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Ouvrir le fichier Parquet\n",
    "parquet_file = pq.ParquetFile(\"taxi_data_snappy.parquet\")\n",
    "\n",
    "print(\"üîç INFORMATIONS G√âN√âRALES:\")\n",
    "print(f\"  Nombre de lignes: {parquet_file.metadata.num_rows:,}\")\n",
    "print(f\"  Nombre de colonnes: {parquet_file.metadata.num_columns}\")\n",
    "print(f\"  Nombre de row groups: {parquet_file.metadata.num_row_groups}\")\n",
    "print(f\"  Taille fichier: {os.path.getsize('taxi_data_snappy.parquet') / 1024**2:.1f} MB\")\n",
    "print(f\"  Compression: {parquet_file.metadata.row_group(0).column(0).compression}\")\n",
    "\n",
    "print(f\"\\nüìä SCHEMA DES COLONNES:\")\n",
    "schema = parquet_file.schema_arrow\n",
    "for i, field in enumerate(schema):\n",
    "    print(f\"  {field.name:25} | {field.type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bf8580-06d3-4636-b0f6-e6e90a0ccea9",
   "metadata": {},
   "source": [
    "### Statistiques des Colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c399deb7-cb9d-4f39-b888-d30d91bef4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìà STATISTIQUES PAR COLONNE\n",
      "============================================================\n",
      "üî¢ STATISTIQUES AUTOMATIQUES:\n",
      "\n",
      "üìä VendorID:\n",
      "  Type Arrow: int32\n",
      "  Type physique: INT32\n",
      "  Compression: SNAPPY\n",
      "  Taille compress√©e: 9,871 bytes\n",
      "  Taille non-compress√©e: 11,538 bytes\n",
      "  Minimum: 1\n",
      "  Maximum: 7\n",
      "  Valeurs nulles: 0\n",
      "\n",
      "üìä tpep_pickup_datetime:\n",
      "  Type Arrow: timestamp[us]\n",
      "  Type physique: INT64\n",
      "  Compression: SNAPPY\n",
      "  Taille compress√©e: 280,822 bytes\n",
      "  Taille non-compress√©e: 337,738 bytes\n",
      "  Minimum: 2024-12-31 20:47:55\n",
      "  Maximum: 2025-01-01 17:02:00\n",
      "  Valeurs nulles: 0\n",
      "\n",
      "üìä tpep_dropoff_datetime:\n",
      "  Type Arrow: timestamp[us]\n",
      "  Type physique: INT64\n",
      "  Compression: SNAPPY\n",
      "  Taille compress√©e: 284,866 bytes\n",
      "  Taille non-compress√©e: 339,850 bytes\n",
      "  Minimum: 2024-12-31 20:54:00\n",
      "  Maximum: 2025-01-02 16:37:05\n",
      "  Valeurs nulles: 0\n",
      "\n",
      "üìä passenger_count:\n",
      "  Type Arrow: double\n",
      "  Type physique: DOUBLE\n",
      "  Compression: SNAPPY\n",
      "  Taille compress√©e: 18,185 bytes\n",
      "  Taille non-compress√©e: 24,065 bytes\n",
      "  Minimum: -0.0\n",
      "  Maximum: 9.0\n",
      "  Valeurs nulles: 0\n",
      "\n",
      "üìä trip_distance:\n",
      "  Type Arrow: double\n",
      "  Type physique: DOUBLE\n",
      "  Compression: SNAPPY\n",
      "  Taille compress√©e: 84,737 bytes\n",
      "  Taille non-compress√©e: 93,499 bytes\n",
      "  Minimum: -0.0\n",
      "  Maximum: 133.3\n",
      "  Valeurs nulles: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìà STATISTIQUES PAR COLONNE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Statistiques du premier row group\n",
    "rg_metadata = parquet_file.metadata.row_group(0)\n",
    "schema_fields = parquet_file.schema_arrow\n",
    "\n",
    "print(\"üî¢ STATISTIQUES AUTOMATIQUES:\")\n",
    "for i in range(min(5, rg_metadata.num_columns)):  # Limiter √† 5 colonnes\n",
    "    col_metadata = rg_metadata.column(i)\n",
    "    stats = col_metadata.statistics\n",
    "    field_name = schema_fields[i].name\n",
    "    field_type = schema_fields[i].type\n",
    "    \n",
    "    print(f\"\\nüìä {col_metadata.path_in_schema}:\")\n",
    "    print(f\"  Type Arrow: {field_type}\")\n",
    "    print(f\"  Type physique: {col_metadata.physical_type}\")\n",
    "    print(f\"  Compression: {col_metadata.compression}\")\n",
    "    print(f\"  Taille compress√©e: {col_metadata.total_compressed_size:,} bytes\")\n",
    "    print(f\"  Taille non-compress√©e: {col_metadata.total_uncompressed_size:,} bytes\")\n",
    "    \n",
    "    if stats:\n",
    "        if stats.has_min_max:\n",
    "            print(f\"  Minimum: {stats.min}\")\n",
    "            print(f\"  Maximum: {stats.max}\")\n",
    "        print(f\"  Valeurs nulles: {stats.null_count:,}\")\n",
    "        if stats.distinct_count:\n",
    "            print(f\"  Valeurs distinctes: {stats.distinct_count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20349e0f-6d50-46d8-94c2-1e0b44c779b8",
   "metadata": {},
   "source": [
    "### R√©sum√© "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eaceca05-4def-496e-bfd1-183b6817f796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üéØ R√âSUM√â\n",
      "============================================================\n",
      "‚úÖ AVANTAGES PARQUET D√âMONTR√âS:\n",
      "  üì¶ Compression: 5.0x plus compact que CSV\n",
      "  ‚ö° Lecture: 11.9x plus rapide que CSV\n",
      "  üîç Filtrage: 15.7x plus rapide avec pr√©dicats\n",
      "  üìä Colonnes: 24.2x plus rapide pour lecture s√©lective\n",
      "  üìã M√©tadonn√©es: Schema automatique, statistiques, compression\n",
      "\n",
      "üéâ D√©monstration termin√©e!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéØ R√âSUM√â\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"‚úÖ AVANTAGES PARQUET D√âMONTR√âS:\")\n",
    "print(f\"  üì¶ Compression: {csv_size/parquet_snappy_size:.1f}x plus compact que CSV\")\n",
    "print(f\"  ‚ö° Lecture: {csv_read_time/parquet_read_time:.1f}x plus rapide que CSV\")\n",
    "print(f\"  üîç Filtrage: {csv_filter_time/parquet_filter_time:.1f}x plus rapide avec pr√©dicats\")\n",
    "print(f\"  üìä Colonnes: {csv_cols_time/parquet_cols_time:.1f}x plus rapide pour lecture s√©lective\")\n",
    "print(\"  üìã M√©tadonn√©es: Schema automatique, statistiques, compression\")\n",
    "\n",
    "print(\"\\nüéâ D√©monstration termin√©e!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa75ee8-ea3a-4f3e-b339-a65bf69860dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
